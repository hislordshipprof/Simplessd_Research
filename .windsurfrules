we are working on a researh paper where we are using reinforcement learning to exploit idle time in storage systems to reduce long-tail latency in flash memory based storage systems  i have implemented the reinforcement learning part of the paper ideally the 3 approach that was highlighted in the paper but we are still missing certain correctness in the implementation that you need to check and fix so our implementation correctly aligns with the paper. so any time you want to make changes reference our paper in the changes which can be found here RL_extracted_clean.md
now we want to implement the various policies that were highlighted in the paper
1. for the Lazy-RTGC policy we need to implement the page mapping scheme that was highlighted in the paperaccoding to the Lazy-RTGC.md paper and according to our original work since that didnt give clear exxplanation, when we run this policy it will be a stand alone so that we will collect the metrics which was outline in our work, which is the average response time and the tail latency, the erase count and also number of page copies and other useful metrics according to the paper and we will log that to our output file giving it the prefix lazy_rtgc_ the various metrics file names we are collecting

2. for the RL baseline policy too we need to check base on what we have done in our code and correctly implement it , we will set a flag to run it alone as well so that we can get the needed metrics according to the paper and output them to the output folder using the prefix rl_baseline_, having the metrics we need and deleting old metrics we dont need, make sure to follow the same metrics we collect for the Lazy-RTGC policy and the algorithm should be in line with our original work

3. Then we will move on to the RL baseline with the Intensive gc implementation according to our original work and we must make sure that the implementation is correct and aligns with the original paper and we will collect the same metrics we collect for the Lazy-RTGC policy and output them to the output folder using the prefix rl_intensive_gc_, having the metrics we need and deleting old metrics we dont need
4. then we will proceed to the Aggressive policy and we must make sure that the implementation is correct and aligns with the original paper handling the two policies that was stated and we will collect the same metrics we collect for the Lazy-RTGC policy and output them to the output folder using the prefix rl_aggressive_, having the metrics we need and deleting old metrics we dont need. 
Always use chain of thought and think step by step following our oiginal paper and that of the paper for the lazy-rtgc policy(using it for that alone) making sure the code we write correctly aligns with the paper.
